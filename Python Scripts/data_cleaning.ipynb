{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from permetrics.regression import Metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso, ElasticNet\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gidja1\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (80,81) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behandling length: 4581\n",
      "Ingrepp length: 4757\n",
      "Diagnos length: 4582\n",
      "Combined length: 4563\n"
     ]
    }
   ],
   "source": [
    "# Lead behandling and select relevant columns\n",
    "behandling = pd.read_csv(Path('../20210324/with_name/behandling_optillfälle.csv'), sep=';')\n",
    "behandling = behandling[['Der_Behandling_PK',\n",
    "                         'Der_Opkort_FK',\n",
    "                         'Der_Anestesikort_FK',\n",
    "                         'Der_Vårdform_FK',\n",
    "                         'Der_Prioritet_FK',\n",
    "                         'BehandlingsStatus',\n",
    "                         'ASAklass',\n",
    "                         'ForberedelsetidStartTidpunkt',\n",
    "                         'ForberedelsetidSlutTidpunkt',\n",
    "                         'PatientÅlderVidOp',\n",
    "                         'Veckodag',\n",
    "                         'Starttimme',\n",
    "                         'BMI',\n",
    "                         'Kroppslängd',\n",
    "                         'Kroppsvikt',\n",
    "                        ]]\n",
    "behandling = behandling[behandling['BehandlingsStatus'] == 'Opererad'] # Remove 'abrutna' operationer as they do not contain all relevant data\n",
    "print(\"Behandling length: {}\".format(len(behandling)))\n",
    "\n",
    "# Load ingrepp and select relevant columns\n",
    "ingrepp = pd.read_csv(Path('../20210324/with_name/op_ingrepp_namn.csv'))\n",
    "ingrepp = ingrepp[['Der_Behandling_PK',\n",
    "                   'Ingreppkod',\n",
    "                   'Primär_Sekundär',\n",
    "                   'Sida',\n",
    "                  ]]\n",
    "ingrepp = ingrepp[ingrepp['Primär_Sekundär'] == 'Primär'] # Might want to include this if we make a more complicated model\n",
    "print(\"Ingrepp length: {}\".format(len(ingrepp)))\n",
    "\n",
    "# Load diagnos and select relevant columns\n",
    "diagnos = pd.read_csv(Path('../20210324/with_name/op_diagnos_namn.csv'))\n",
    "diagnos = diagnos[['Der_Behandling_PK',\n",
    "                   'Diagnoskod',\n",
    "                   'Primär_Sekundär',\n",
    "                  ]]\n",
    "diagnos = diagnos[diagnos['Primär_Sekundär'] == 'Primär'] # Might want to include this if we make a more complicated model\n",
    "print(\"Diagnos length: {}\".format(len(diagnos)))\n",
    "\n",
    "# Combine the data frames\n",
    "combined_df = behandling.merge(diagnos, on='Der_Behandling_PK').merge(ingrepp, on='Der_Behandling_PK')\n",
    "print(\"Combined length: {}\".format(len(combined_df)))\n",
    "\n",
    "# Calculate and add time to the dataframe\n",
    "\n",
    "# Bad algoritm for checking min and max time of förbereds\n",
    "start = combined_df[\"ForberedelsetidStartTidpunkt\"].dropna()\n",
    "slut = combined_df[\"ForberedelsetidSlutTidpunkt\"].dropna()\n",
    "\n",
    "start_times = []\n",
    "for time in start:\n",
    "    minn = int(time[-9:-7])\n",
    "    hour = int(time[-12:-10])\n",
    "    minutes = hour*60 + minn\n",
    "    start_times.append(minutes)\n",
    "    \n",
    "stop_times = []\n",
    "for time in slut:\n",
    "    minn = int(time[-9:-7])\n",
    "    hour = int(time[-12:-10])\n",
    "    minutes = hour*60 + minn\n",
    "    stop_times.append(minutes)\n",
    "\n",
    "times = []\n",
    "for i in range(len(start_times)):\n",
    "    #print(stop_times[i], start_times[i], stop_times[i] - start_times[i])\n",
    "    times.append(stop_times[i] - start_times[i])\n",
    "    \n",
    "# Add total time to dataframe\n",
    "combined_df['time'] = times\n",
    "\n",
    "# Remove all fetuers we don't want\n",
    "features_df = combined_df.drop([\"Der_Behandling_PK\", \n",
    "                               \"Der_Opkort_FK\",\n",
    "                               \"Der_Anestesikort_FK\",\n",
    "                               \"BehandlingsStatus\",\n",
    "                               \"ForberedelsetidStartTidpunkt\",\n",
    "                               \"ForberedelsetidSlutTidpunkt\",\n",
    "                               \"Primär_Sekundär_x\",\n",
    "                               \"Primär_Sekundär_y\",\n",
    "                            ], axis='columns')\n",
    "\n",
    "ingrepp_plural = {}\n",
    "ingreppsgrupp = []\n",
    "for index, row in combined_df.iterrows():\n",
    "    ingrepp = row['Ingreppkod']\n",
    "    ingrepp_group = ingrepp[0:2]\n",
    "    ingreppsgrupp.append(ingrepp_group)\n",
    "features_df['IngreppsGrupp'] = ingreppsgrupp\n",
    "\n",
    "diagnosgrupp = []\n",
    "for index, row in combined_df.iterrows():\n",
    "    diagnos = row['Diagnoskod']\n",
    "    diagnos_grupp = diagnos[0]\n",
    "    diagnosgrupp.append(diagnos_grupp)\n",
    "features_df['DiagnosGrupp'] = diagnosgrupp\n",
    "\n",
    "'''\n",
    "diagnosgrupper = {}\n",
    "for diagnosgrupp, diagnosgrupp_df in features_df.groupby('DiagnosGrupp'):\n",
    "    diagnosgrupper[diagnosgrupp] = diagnosgrupp_df\n",
    "grupp_mean = []\n",
    "grupp_std = []\n",
    "for grupp in diagnosgrupper.keys():\n",
    "    df = features_df[features_df['DiagnosGrupp'] == grupp]\n",
    "    grupp_mean.append(df['time'].mean())\n",
    "    grupp_std.append(df['time'].std())\n",
    "#plt.errorbar(diagnosgrupper.keys(), grupp_mean, grupp_std, marker='o', linestyle='None', capsize=3)\n",
    "\n",
    "ingreppsgrupper = {}\n",
    "for ingreppsgrupp, ingreppsgrupp_df in features_df.groupby('IngreppsGrupp'):\n",
    "    ingreppsgrupper[ingreppsgrupp] = ingreppsgrupp_df\n",
    "grupp_mean = []\n",
    "grupp_std = []\n",
    "for grupp in ingreppsgrupper.keys():\n",
    "    df = features_df[features_df['IngreppsGrupp'] == grupp]\n",
    "    grupp_mean.append(df['time'].mean())\n",
    "    grupp_std.append(df['time'].std())\n",
    "#plt.errorbar(ingreppsgrupper.keys(), grupp_mean, grupp_std, marker='o', linestyle='None', capsize=3)\n",
    "'''\n",
    "features_df = features_df.drop([\"Diagnoskod\", \"Ingreppkod\", 'Kroppslängd', 'Kroppsvikt', 'Veckodag'], axis='columns')\n",
    "features_df = features_df[features_df['IngreppsGrupp'].isin(['TN', 'NC', 'NH', 'NB', 'NG', 'NF', 'ND'])]\n",
    "\n",
    "# Instansiate Metrics so we can use MAAPE later\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Der_Vårdform_FK</th>\n",
       "      <th>Der_Prioritet_FK</th>\n",
       "      <th>ASAklass</th>\n",
       "      <th>PatientÅlderVidOp</th>\n",
       "      <th>Starttimme</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Sida</th>\n",
       "      <th>time</th>\n",
       "      <th>IngreppsGrupp</th>\n",
       "      <th>DiagnosGrupp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29434.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Höger</td>\n",
       "      <td>116</td>\n",
       "      <td>TN</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16841.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Höger</td>\n",
       "      <td>29</td>\n",
       "      <td>TN</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15658.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>Vänster</td>\n",
       "      <td>88</td>\n",
       "      <td>NC</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27854.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>Vänster</td>\n",
       "      <td>46</td>\n",
       "      <td>NH</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21777.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>Vänster</td>\n",
       "      <td>95</td>\n",
       "      <td>NC</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Der_Vårdform_FK  Der_Prioritet_FK  ASAklass  PatientÅlderVidOp  Starttimme  \\\n",
       "0                2                 2       NaN            29434.0         8.0   \n",
       "1                2                 3       NaN            16841.0         7.0   \n",
       "2                2                 1       3.0            15658.0        16.0   \n",
       "3                2                 5       1.0            27854.0        11.0   \n",
       "4                2                 6       NaN            21777.0        10.0   \n",
       "\n",
       "    BMI     Sida  time IngreppsGrupp DiagnosGrupp  \n",
       "0   NaN    Höger   116            TN            T  \n",
       "1   NaN    Höger    29            TN            M  \n",
       "2  24.4  Vänster    88            NC            S  \n",
       "3  29.1  Vänster    46            NH            T  \n",
       "4  24.4  Vänster    95            NC            M  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle NaN (ONLY DO ONE OF THESE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = features_df[\"time\"]\n",
    "X = features_df.drop(\"time\", axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove rows with NaN** (Good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3708\n"
     ]
    }
   ],
   "source": [
    "features_df = features_df.dropna()\n",
    "print(len(features_df))\n",
    "y = features_df[\"time\"]\n",
    "X = features_df.drop(\"time\", axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace NaN with 0** (Bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(0)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple Imputer** (Using most frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp.fit(X)\n",
    "X = imp.transform(X)\n",
    "X = pd.DataFrame(X).transpose()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = KNNImputer(missing_values=np.nan, n_neighbors=5)\n",
    "imp.fit(X)\n",
    "X = imp.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding (ONLY DO ONE OF THESE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use One Hot Encoding to encode \"sida\" and \"ingreppsgrupp\"** (This seems to be the better alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ordinal Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = features_df['time']\n",
    "#X = features_df.drop('time', axis='columns')\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(X)\n",
    "X = enc.transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs error:38.29162641919161, % error: 0.34\n"
     ]
    }
   ],
   "source": [
    "# Try dummyregressor as a basecase, anything worse than this is really terrible\n",
    "regr = DummyRegressor()\n",
    "regr.fit(X_train, y_train)\n",
    "pred = regr.predict(X_test)\n",
    "abs_error = mean_squared_error(y_test, pred, squared=False)\n",
    "percentage_error = metrics.mean_arctangent_absolute_percentage_error(clean=True, y_pred=np.array(pred), y_true=np.array(y_test))\n",
    "print(f'abs error:{abs_error}, % error: {percentage_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs error:46.75895866836355, % error: 0.331\n"
     ]
    }
   ],
   "source": [
    "regr = DecisionTreeRegressor()\n",
    "regr.fit(X_train, y_train)\n",
    "pred = regr.predict(X_test)\n",
    "abs_error = mean_squared_error(y_test, pred, squared=False)\n",
    "percentage_error = metrics.mean_arctangent_absolute_percentage_error(clean=True, y_pred=np.array(pred), y_true=np.array(y_test))\n",
    "print(f'abs error:{abs_error}, % error: {percentage_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs error:33.32669863224349, % error: 0.272\n"
     ]
    }
   ],
   "source": [
    "forest_regr = RandomForestRegressor(max_depth=22)\n",
    "forest_regr.fit(X_train, y_train)\n",
    "pred = forest_regr.predict(X_test)\n",
    "abs_error = mean_squared_error(y_test, pred, squared=False)\n",
    "percentage_error = metrics.mean_arctangent_absolute_percentage_error(clean=True, y_pred=np.array(pred), y_true=np.array(y_test))\n",
    "print(f'abs error:{abs_error}, % error: {percentage_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs error:31.76912603883179, % error: 0.265\n"
     ]
    }
   ],
   "source": [
    "boost_regr = GradientBoostingRegressor(max_depth=3,)\n",
    "boost_regr.fit(X_train, y_train)\n",
    "pred = boost_regr.predict(X_test)\n",
    "abs_error = mean_squared_error(y_test, pred, squared=False)\n",
    "percentage_error = metrics.mean_arctangent_absolute_percentage_error(clean=True, y_pred=np.array(pred), y_true=np.array(y_test))\n",
    "print(f'abs error:{abs_error}, % error: {percentage_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs error:38.29116238181593, % error: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gidja1\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "regr = MLPRegressor(random_state=1, activation='logistic', learning_rate='adaptive', )\n",
    "regr.fit(X_train, y_train)\n",
    "pred = regr.predict(X_test)\n",
    "abs_error = mean_squared_error(y_test, pred, squared=False)\n",
    "percentage_error = metrics.mean_arctangent_absolute_percentage_error(clean=True, y_pred=np.array(pred), y_true=np.array(y_test))\n",
    "print(f'abs error:{abs_error}, % error: {percentage_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs error:34.69773020618116, % error: 0.301\n"
     ]
    }
   ],
   "source": [
    "regr = LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "pred = regr.predict(X_test)\n",
    "abs_error = mean_squared_error(y_test, pred, squared=False)\n",
    "percentage_error = metrics.mean_arctangent_absolute_percentage_error(clean=True, y_pred=np.array(pred), y_true=np.array(y_test))\n",
    "print(f'abs error:{abs_error}, % error: {percentage_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(31, input_dim=31, kernel_initializer='normal', activation='relu')) #Input layer\n",
    "    model.add(Dense(10, kernel_initializer='normal', activation='relu')) #Input layer\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='relu')) #Output layer\n",
    "    # Compile model\n",
    "    opt = keras.optimizers.Adam(clipnorm=1, learning_rate=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return model\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=1000, batch_size=32, verbose=1)\n",
    "kfold = KFold(n_splits=10)\n",
    "#results = cross_val_score(estimator, X_train, y_train, cv=kfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avrg mean_error_sqr: -6808.340002441406\n"
     ]
    }
   ],
   "source": [
    "avrg = sum(results)/len(results)\n",
    "print(f'avrg mean_error_sqr: {avrg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "87/87 [==============================] - 1s 2ms/step - loss: 10338.9371\n",
      "Epoch 2/1000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10005.2634\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10150.5349\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10621.6878\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10407.3435\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10117.5576\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10102.3414\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10053.7564\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10526.1427\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10268.3110\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10193.9148\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10283.9092\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10111.7676\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10361.6306\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10190.3363\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10155.8467\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10100.2530\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10010.4044\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10125.6273\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10225.7389\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10222.3292\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 9963.4072\n",
      "Epoch 23/1000\n",
      "27/87 [========>.....................] - ETA: 0s - loss: 10438.1079"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-957a6e4ab23f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)\n",
    "pred = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = forest_regr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
